{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ccClub week9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wesley1110/Crawler/blob/main/ccClub_week9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I51gtbOaWvmA"
      },
      "source": [
        "# 爬蟲大補帖 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnoEE9QfoHiU"
      },
      "source": [
        "## 重點事項宣布\n",
        "\n",
        "12/02 23:59 是 Proposal 「建議」繳交時限，早點繳交助教們可以早點提供幫助"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf54twVXWzIx"
      },
      "source": [
        "## API\n",
        "### API 是什麼\n",
        "* Application Programming Interface 的縮寫，中文為「應用程式介面」\n",
        "* API 會接收你的請求並告訴系統，再把系統的回應回傳給你\n",
        "* 使用 API 時，不需要了解內部的程式運作，只要告訴 API 必要資訊就可以得到結果\n",
        "* API 回傳的常是 json 或 XML 格式的資料\n",
        "\n",
        "### Json\n",
        "* Json Viewer : http://jsonviewer.stack.hu/ \n",
        "* Json 跟 Python 裡的字典很像，由 key: value 為一對所組成\n",
        "* 使用 Python 內建的 json 套件，解析 json 格式資料\n",
        "```\n",
        "import json\n",
        "```\n",
        "* json 轉 dict `json.loads()`\n",
        "* dict 轉 json `json.dumps()`\n",
        "* requests 解析 json `re.json()`\n",
        "\n",
        "### 向 API 請求時傳入參數\n",
        "```\n",
        "my_params = {\"params1\" : \"value1\", \"params2\" : \"value2\"}\n",
        "requests.get(url, params = my_params)\n",
        "```\n",
        "\n",
        "### Dcard API\n",
        "* 看板資訊：https://www.dcard.tw/service/api/v2/forums\n",
        "* 全部文章資訊：https://www.dcard.tw/service/api/v2/posts\n",
        "* 看板內文章資訊：https://www.dcard.tw/service/api/v2/forums/看板/posts\n",
        "* 特定文章內容：https://www.dcard.tw/service/api/v2/posts/文章ID\n",
        "* 文章內連結：https://www.dcard.tw/service/api/v2/posts/文章ID/links\n",
        "* 文章內留言：https://www.dcard.tw/service/api/v2/posts/文章ID/comments\n",
        "\n",
        "### Dcard API 查詢參數\n",
        "```\n",
        "popular = true  #依照熱門程度排序\n",
        "popular = false #依照發布時間排序\n",
        "limit = 10 #想要爬的文章數量（一定要設定，避免被封鎖）\n",
        "```\n",
        "\n",
        "### time 套件\n",
        "為了避免被誤認為惡意攻擊，我們需要在爬蟲中加上一小段間隔時間\n",
        "或是後面的 selenium 用來等元素出現\n",
        "```\n",
        "import time\n",
        "time.sleep(2)\n",
        "```\n",
        "\n",
        "### 爬蟲實戰\n",
        "請找出臺大板熱門排行前10名的文章，列出其文章標題及發文時間，並彙整所有回應內容\n",
        "\n",
        "課後練習：請問在 Dcard 熱門文章前 50 名中，哪個板的文章出現最多次？並列出那些文章的標題"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NoojbN-Wy0t",
        "outputId": "cfce2f3a-6d2b-4426-e7de-b63c2efbd237"
      },
      "source": [
        "import requests\n",
        "import time as t\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url_api = \"https://www.dcard.tw/service/api/v2/forums/ntu/posts/\"\n",
        "my_params = {\"popular\" : \"true\", \"limit\" : 10}\n",
        "ntu = requests.get(url_api, params = my_params).json()\n",
        "for post in ntu:\n",
        "    id, title, time = post[\"id\"], post[\"title\"], post[\"createdAt\"]\n",
        "    comment_api = f\"https://www.dcard.tw/service/api/v2/posts/{id}/comments\"\n",
        "    # print(comment_api)\n",
        "    # break\n",
        "    comments = requests.get(comment_api).json()\n",
        "    comments_lst = []\n",
        "    for row in comments:\n",
        "      if type(row) != str:\n",
        "        comments_lst.append(row.get(\"content\", \"no comment\"))\n",
        "    print(title, time, comments_lst, sep = \"\\n\")\n",
        "    print(\"--------------------------------------------\")\n",
        "    t.sleep(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#公告 即日起開放試用私訊功能\n",
            "2021-07-30T06:42:30.153Z\n",
            "['no comment', 'no comment', '嗨(´；ω；｀)', 'B3 你沒有開接受私訊，還好我有嘿嘿', 'no comment', '嗨', '快來私訊我跟我當朋友真心不騙', '真的可以私訊?', '嗨', '這裡就可以', '好酷', 'no comment']\n",
            "--------------------------------------------\n",
            "就算是直女也會喜歡漂亮女生\n",
            "2021-11-24T03:40:13.662Z\n",
            "['羨慕', '喜歡跟漂亮女生貼貼🥰', '我怎麼昨天也從我朋友口中聽到幾乎一樣的言論xD你是不是我朋友啊(⁎⁍̴̛ᴗ⁍̴̛⁎)', '或許本來帥哥就不多人啦，但男生極少數人會化妝，如果女生都素顏的話，好看的人數也會降低吧', '性別跟長相應該接近獨立分配\\n所以漂亮女生比例跟帥帥男生比例應該差不多\\n漂亮女生比例高純粹是女生的化妝造成的假象']\n",
            "--------------------------------------------\n",
            "讀書讀到狗屁股裡去\n",
            "2021-11-24T18:40:26.922Z\n",
            "['這是我發的吧..', '培養失敗就應該直接不讓你畢業阿 看是要退學去哪這樣', '只有獸醫系會讀到狗屁股裡面去，而且還很專業ㄋ', '我想知道你的科系，因為我覺得我也有點這樣', '這是甚麼科技技術的滲透大腦嗎\\n為甚麼D卡可以自動幫我發文', 'B2\\n培養失敗只代表我沒有變成這一行的人才，不代表我自己畢不了業啊，只是浪費我的時間而已\\n硬逼我去讀考完就會忘的東西，還不如放了我，讓我把時間拿去對社會貢獻', '忘了很正常吧\\n腦袋每天都會清理不重要的資訊\\n對腦子來說 平常用不到的東西都不重要\\n但這不代表沒留下任何東西\\n當你再次要用到的時候\\n學習速度會快很多\\n不是從0開始', 'B3 你484上台大便好快樂粉專主ㄚ', '懷疑是我發的\\n高中的反而記得\\n我愛填鴨教育', '國高中那種讀書根本在浪費時間==', '其他的我贊成 但退化到高中都不如太扯 吸收課外知識很難嗎？ 更何況高中那種填鴨教育算啥知識', 'B11\\n填鴨式的知識不也是知識嗎？高三畢業時至少還背的出哪塊大陸是什麼氣候類型，排列組合超屌，英文作文能力也不錯，生物都還記得\\n\\n大學時候課外知識當然有，我說的是知識比高中時還“少”，高中會的東西可多了，所以早點放了我讓我用課外能力去貢獻社會不行嗎\\n\\nB10\\n對我來說讀現在的東西也是浪費時間，比高中讀起來更痛苦，考完當天一樣秒忘，然後未來也用不到\\n\\nB7\\n複習速度快也敵不過現在需要用到的範圍，大二最重的課和大三最重的課要在下次考試前全部讀回來，怎麼可能....\\n然後我這種情況，不是從0開始，也頂多從0.1開始', '通報 📢\\n好像有人對這篇文章有新想法唷，快來去看看！\\n https://www.dcard.tw/f/nchu/p/237530733', '我讀到大四 還是一樣考完就忘記喔', '我也是 還好逃去cs 了', 'B6 你直接退學就自己放過自己了 沒人逼你畢業', '我早上讀書，晚上打手槍都射光光', 'b16 \\n笑死，你是不是覺得這樣講話很有成就感，有高人一等的感覺？\\n\\n你的邏輯就像是跟社畜說沒人逼你辛苦賺錢 去辭職，跟憂鬱症說看開一點，跟魯蛇說開朗一點去認識異性', 'B8 不是ㄛ 但年紀一樣就是ㄌ', 'B3 欸 可是狗屁股也是考完就忘啊']\n",
            "--------------------------------------------\n",
            "可以麻煩在總圖地下室不要設鬧鐘嗎\n",
            "2021-11-24T08:54:21.649Z\n",
            "['https://i.imgur.com/Nk8DAml.jpg', '真好 只剩最後一科\\n我每週都有無數的小考+期考+project\\n\\U0001f972', '有考慮過每週都期中的人的感受嗎（大哭）', 'B2 可是我有三科期末100%⋯', '總圖自習室設鬧鐘的他媽我都懷疑生下來的時候把小孩摔到地上變成低能兒\\n有夠吵\\n\\n而且幹我期中到下禮拜機掰', '希望他娘葬禮的時候鬧鐘也會響', '已經考完了，等等把我的鬧鐘設六點放在總圖然後跑回宿舍睡到自然醒 嘿嘿', '我都設無聲震動鬧鐘放到自己屁股底下，震的時候不會影響到別人，還會有點舒服', '我在總圖凌晨的時候會這樣\\n對不起😰', 'B2 +1\\U0001f972', '祝期中all pass 微積分期考96 穩A+的高一仔替你加油', 'B8 笑死... 是多舒服啦下次來試試看😂', '不客氣\\nhttps://i.imgur.com/uP4LuJZ.jpg', '笑死，是沒見過在總圖用自動削鉛筆機的嗎？還有打呼怪', '可以用午睡鬧鐘app 那可以接耳機就不會吵到別人', 'b15 但要記得把勿擾模式關掉、震動打開！']\n",
            "--------------------------------------------\n",
            "為了學姐的幸福，我還應該衝一波嗎？\n",
            "2021-11-24T15:37:18.559Z\n",
            "['你怎麼知道學姐沒有喜歡那個學長\\n她說不定也在暈船？', '感覺女生是海王', 'B1 \\n好像也有可能耶\\n被你一講我更想哭了\\n心好痛卻無能為力⋯⋯\\n\\nB2\\n應該不是吧\\n據我所知，她異性朋友蠻少的', '異性出遊過夜超曖昧的好嗎\\n你去了也是當陪襯的花童\\n請拾起你最後的尊嚴不要跟去', '可以做愛嗎', 'B4 \\n被你這麼一講\\n好奇如果跟去的話會發生什麼事😂\\n\\nB5\\n窩不知道.jpg', '海海人生', '我猜\\n她對他有興趣\\n身為原破情況接近的我\\n每次推斷對方沒對象下週或下月直接脫魯\\n我要把這種好運過給你', '跟你爸講說不定會把你踹去台中@@\\n我覺得喜歡就去搶誒有拚過才能服輸啊\\n海王又怎樣啊你就暈了咩', '唯一的辦法就是你先去把學長搶走了', '不去的話他們應該直接捉i了吧 三天兩夜兩人獨處 一個正常男生應該都會想進一步發生些什麼吧\\n去的話還有機會攔截 最好在什麼都沒發生前丟直球了結吧 不要讓自己那麼可悲\\n然後話說如果都台大的 你po校版她不會看到嗎', '衝了還有機會，不衝可能什麼都沒有了', '人生不留遺憾！\\n衝啊！比風還要更快！\\n摩多！摩多嗨呀酷！\\n你是電！你是光！你是唯一的神話！', '一起去說不定有機會解鎖3P成就', 'B7 \\nQQ\\n\\nB8\\n呃⋯謝囉^^\\n那你都怎麼走出這種心情的？\\n\\nB9\\n這種事哪能跟家人講啊\\n跟去真的蠻丟臉的\\n我爸大概只會叫我放棄她\\n然後去吃家庭聚餐吧ಥ_ಥ\\n\\nB10\\n那晚上來跟學長告白\\n你要什麼好建議嗎哈哈⋯哈\\n\\nB11\\n丟直球是指直接告白嗎？\\n但在對方沒有喜歡自己的情況下\\n告白會有用嗎？\\n學姐她沒有在用Dcard\\n所以她應該看不到\\n除非她的朋友傳給她看XD\\n\\nB12 B13\\n感謝你們誒哈哈哈\\n\\nB14\\n學姐會比較想在一旁看男上加男', 'B15 吾逼八也\\n習慣了：）幹', 'B15 我覺得你爸會叫你去追欸\\n因為我爸就講過一樣的話⋯⋯', 'B17 可能不是每個人的爸爸都這麼鏘得可愛XD\\n以後我兒子這樣我載也載他下台中 大不了大家一起下去邊觀賞愛情劇邊吃家庭聚餐 B15喜歡就追啊別慫 你不尷尬就是學長尷尬了', '衝啦', 'B8 推正解，原po請服用暈船藥，要嘛直球對決，要嘛退出。有時候就是這樣，你還在那邊墨跡的時候對手就先聲奪人了，下次記得快一點', '3P和在家尻 你選一個', 'B18 我媽都常常把老爸到處沾花惹草之類的挖苦話掛嘴邊\\n大概是每次都被倒追吧\\n（幹沃需要啊喂', 'B20 支援暈船藥', 'B21 在家一邊尻一邊三匹', '聽我的正解 \\n現在開始不讀不回冷他\\n你地位比她低  很難吸引人', '不用衝，告訴我學姊的聯絡方式我幫你衝。', 'no comment']\n",
            "--------------------------------------------\n",
            "覺得自己是垃圾怎麼辦？\n",
            "2021-11-24T16:41:15.379Z\n",
            "['中二病發作', '要來杯泰奶嗎，公館好像有不錯的泰奶。', 'B1 如果是的話，要怎麼治？\\nB2 沒心情喝😩', '好中二的文章\\n看了尷尬', 'B4 是嗎，我是很認真的', '也許你的感受是對的', '去工作板問問 沒出過社會 吃過苦才會這樣想\\n學歷是一時 幾年 不會一生跟著你 看開點\\n現在是百歲時代 我們以整數來計算\\n80-20=60 你往後的60年 不可能靠那張學歷\\n個性 各人特質才是決定你的命運\\n碩士 博士畢業的你 還不是要被國小 五專的老板管', 'B7 謝謝回覆，不過我只的不是學歷\\n\\n我一直想跟上面的強者競爭，但每次都被擊落，無法達到他們的高度\\n可是往下比又可以贏過很多的人\\n但是往下比並不會讓我有任何優越感、自信\\n反而讓我覺得自己更可悲，只能往下比\\n我依舊還是那位爬不到上面的人類\\n我依舊是處在極度沒自信，害怕被他人拆穿看破手腳的人', 'B6 細思極恐', '換個角度想\\n或許有些時候不一定要爬到最高處也沒關係的', '好有感⋯⋯覺得就是差那一步把自己變得很強，那麼一切都會回到最顛峰的狀態的感覺 加油！！', '享受過程～', '說一句現實的 人要有自知之明\\n承認自己不夠好 也要知道自己哪裡好\\n加油加油...', '我不想上樓 讓我當白癡\\n不要啟蒙我 讓我當白癡', '不要耍笨好不好，我相信你總會有比別人優秀的地方的，可是不是像個沒社會化的中二屁孩一樣耍猴', '王你媽者 你應該趕快認識到自己在乎的這些東西根本都沒意義', '大家一定都會有覺得自己是垃圾的時候 但如果沒有這種時候 你要怎麼變強', '你需要放下身段，接納自己的不完美與不足，長期我們都憑藉著那種贏過別人的虛榮感過生活，但是這種感覺是不實際的、不踏實的，終究會有盡頭，不可能有人一輩子能夠贏過所有人，老一輩總是說：人比人氣死人，我起初是不信的，畢竟，沒嚐過比輸的感覺，但到了高中大學，身邊就是有人你永遠無法企及，這時候難道要盲目的去追隨他們嗎？那所謂的社會期待跟贏的虛榮感最後能帶給你什麼？好比說，剛考上明星高中或是台大，身邊總是出現不少恭維讚賞聲，那段時間會感覺自己非常的快樂，但過了一段時間，這種快樂感會慢慢轉換成一種空虛，極其空洞的空虛，我那時後就明白：人生不能靠著這種無意義的虛榮心過生活，心靈不會真正的富足，我想，若無法慢慢的放下，那種感覺只會一點一滴的侵蝕你的心靈吧，焦慮、恐懼、壓力大、害怕不完美種種跡象都有可能發生，我相信台大人都會有這種感覺，即便是再優秀的人都有可能擔心，何不停止這種想法，去追尋真正會讓你快樂的事情呢？ \\n成功，絕對不是你贏過多少人，而是你做到了你想做的事情，會讓你真正快樂的事情，心靈富足的事情，學習放下成敗觀去看世界，世界或許比你想的更美好！', '這種文是不是都是因為自己是從中南部的高中上來的啊\\n想當初自己是小地區的小霸王\\n\\n但台北的高中一直以來都是競爭激烈\\n身邊的強者總是強敵環伺\\n上大學都見怪不怪了吧\\n看清現實比較重要\\n台北的人去你們那裡也都可以當小霸王\\n你並不是最特別的那個\\n只是你們沒見識過而已', '私わゴミです', '刷人生首抽', 'B20 いいえ、私こそゴミです', '未看先猜是電資的', '當初讀附中前 \\n也以為自己是超級王者😬\\n只是不幸會考殞落至第二志願 🥺\\n成為階下囚 建中的小弟 😱\\n我不甘只成為獨霸一方的附中地頭蛇 🤑\\n為找回霸王色的強大與自信\\U0001f978\\n最後奮力考上台大 🥳\\n證明自己不是一坨渣渣的三腳貓🤬', '你不是垃圾 你只是顆黑色小籠包\\nhttps://i.imgur.com/hjx62z0.jpg', '成績只是一部分啊\\n你可能在社團做事很負責\\n或是看了很多課外書\\n這些都是優點啊\\n不要只侷限在考試裡']\n",
            "--------------------------------------------\n",
            "畢業團拍\n",
            "2021-11-24T03:45:04.780Z\n",
            "['以為是我發的…..', '轉系生沒去+1', '延畢生根本直接不拍了QQ', '我也沒去', '我去年就在想這個問題了\\n我覺得沒有圈圈真的別去 \\n因為大家都會有小圈圈會留下來自己拍\\n幫你發現只有你沒有小圈圈的時候真的很可憐…要自己穿著脫下學士服默默翻滾退場\\n你問我為什麼要脫學士服？\\n因為穿在校園大家就會知道我是落單的畢業森🥺🥺🥺', '還好我直接休學了\\n不用再順從別人、當團體裡不重要的哪個\\n做自己好自在😌', '不熟就別去\\n免得讓自己難堪\\n我自己覺得團拍沒什麼意義', '我來分享一下我的經驗好了：\\n好不容易轉到經濟，就開始線上課，然後線上課...\\n所以我在這屆大四都沒有甚麼認識的人，\\n不過我還是很羨慕穿白襯衫拍畢業服的照片\\n所以就硬著頭皮去了\\n打開社交模式，好天氣 一起拍照\\n附近的人領子歪了也很熱心地跟對方說，\\n拍照站了很久就跟隔壁亂聊天\\n只要我不尬 尬的就是別人XD\\n然後感謝當天讓我亂入的幾個小圈圈，\\n也讓我順利拍到了幾張合照\\n還遇到以前其他地方認識的人\\n覺得滿意了，跟大家揮手掰掰，大家也都很熱情\\n圓滿的結束了拍照日\\nhttps://i.imgur.com/9mlOvKG.jpg', '通報 📢\\n好像有人對這篇文章有新想法唷，快來去看看！\\n https://www.dcard.tw/f/nchu/p/237530742', 'B8 好勇敢（hug']\n",
            "--------------------------------------------\n",
            "好喜歡…\n",
            "2021-11-24T16:26:07.545Z\n",
            "['為何是7個…巧合嗎…我不這麼認為…', '從官網就可以訂了噢（昨天剛去取貨的人', '這個真的很可愛（˶‾᷄ ⁻̫ ‾᷅˵）\\n我那天也買了好幾個', '顏色好多喔 希望可以出個貼紙']\n",
            "--------------------------------------------\n",
            "給自以為只有自己有路權的低能兒\n",
            "2021-11-24T10:53:25.950Z\n",
            "[]\n",
            "--------------------------------------------\n",
            "臺大渣男原po的第二篇文\n",
            "2021-11-24T00:55:05.594Z\n",
            "['推起來', '好噁', 'no comment', '沒人在乎誰渣男誰被渣啦\\n反正你們都長不好看，長得好看的根本不在這個校園裡，你們是沒用過哀居嗎.....', '這洗得乾淨喔', '洗的很乾淨欸', 'no comment', 'B4\\n每次都是我跳出來嘴顏值，剛剛點開還以為這是我留言的🙃\\n說，你是不是我的分身？', '什麼圖啊？\\n我沒看到']\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7nYUDxfWkCw",
        "outputId": "c32f2e54-f524-4645-a5b3-381c25b08994"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "api = \"https://www.dcard.tw/service/api/v2/posts\"\n",
        "my_params = {\"popular\" : \"true\", \"limit\" : 50}\n",
        "# https://www.dcard.tw/service/api/v2/posts?popular=true&limit=50\n",
        "top_50 = requests.get(api, params = my_params).json()\n",
        "\n",
        "forums={}\n",
        "for post in top_50:\n",
        "    forum = post[\"forumName\"]\n",
        "    if forum in forums:\n",
        "        forums[forum] += 1\n",
        "    else:\n",
        "        forums[forum] = 1\n",
        "\n",
        "forums_sorted = sorted(forums.items(), key=lambda x:x[1], reverse=True)\n",
        "forum_top1 = forums_sorted[0][0]\n",
        "print(f\"看板：{forum_top1}\")\n",
        "print(\"---------------------------------------\")\n",
        "\n",
        "for post in top_50:\n",
        "    if post[\"forumName\"] == forum_top1:\n",
        "        print(post['title'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "看板：感情\n",
            "---------------------------------------\n",
            "冬天告白的成功率是不是比較高\n",
            "男友要求發生關係\n",
            "沒告白先被拒絕\n",
            "第一次交往 是我太敏感 還是⋯⋯？\n",
            "和男友的愛愛訊息\n",
            "要怎樣才能知道肚子裡的寶寶是誰的\n",
            "前幾天發現男友的秘密\n",
            "被男友硬上了但是有爽到可以告他嗎\n",
            "一高遮三醜是真的\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcBZXsrKHebb"
      },
      "source": [
        "## GET & POST\n",
        "* GET\n",
        "  * 只拿資料，不會對資料做修改\n",
        "  * 把資料放在 header 傳送\n",
        "  * 發送請求的網址會帶有送出的資料 eg. https://www.dcard.tw/service/api/v2/posts?popular=true&limit=50\n",
        "  * 像是寫明信片，資料寫在外面\n",
        "* POST\n",
        "  * 可改動資料(新增、修改、刪除)\n",
        "  * 把資料放在 body 傳送\n",
        "  * 傳遞資料時網址不改變\n",
        "  * 像是寫信件，除了信封外可以寫，信封內也可以放東西\n",
        "\n",
        "### POST 請求\n",
        "```\n",
        "requests.post(url , data = d) # data 就是 body\n",
        "```\n",
        "\n",
        "### 爬蟲實戰\n",
        "期貨查詢：http://www.taifex.com.tw/cht/3/futDailyMarketReport\n",
        "\n",
        "爬蟲目標：至交易資訊頁面查詢臺股期貨(TX) 2021/11/17 當日交易行情\n",
        "\n",
        "課後練習：爬取小型臺指(MTX)最近一個交易日盤後交易時段的交易資訊，並找出成交量最大的期貨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ob2I3QhY1aS",
        "outputId": "3f888f6c-c230-41ed-cf10-d68b88211292"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "url = 'https://www.taifex.com.tw/cht/3/futDailyMarketReport'\n",
        "data = {'queryType': 2,\n",
        "        'marketCode': 0,\n",
        "        'commodity_id': 'TX',\n",
        "        'queryDate': '2021/11/17',\n",
        "        'MarketCode': 0,\n",
        "        'commodity_idt': 'TX'}\n",
        "re = requests.post(url, data=data, verify = False) \n",
        "soup = BeautifulSoup(re.text, 'html.parser')\n",
        "table = soup.find('table', {'class': 'table_f'})\n",
        "thead = table.find('tr')\n",
        "\n",
        "title = []\n",
        "for th in thead.find_all('th')[:8]:\n",
        "    title.append(th.text)\n",
        "print(\" \".join(title))\n",
        "future_list = []\n",
        "for row in table.find_all('tr')[1:-1]:\n",
        "    future_info = []\n",
        "    for td in row.find_all('td')[:2]:\n",
        "        future_info.append(td.text.strip())\n",
        "    for td in row.find_all('td')[2:7]:\n",
        "        future_info.append(int(td.text.strip().replace('▲', '').replace('▼', '')))\n",
        "    for td in row.find_all('td')[7:8]:\n",
        "        future_info.append(float(td.text.strip().replace('▲', '').replace('▼', '').replace('%','')))\n",
        "    future_list.append(future_info)\n",
        "\n",
        "future_list.sort(key = lambda x: x[7])\n",
        "for i in future_list:\n",
        "    print(\" \".join([str(s) for s in i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "契約 到期月份(週別) 開盤價 最高價 最低價 最後成交價 漲跌價 漲跌%\n",
            "TX 202111 17711 17761 17678 17722 24 0.14\n",
            "TX 202209 17059 17099 17059 17099 62 0.36\n",
            "TX 202201 17658 17711 17615 17710 77 0.44\n",
            "TX 202206 17456 17508 17436 17508 76 0.44\n",
            "TX 202112 17710 17764 17661 17764 83 0.47\n",
            "TX 202203 17569 17629 17543 17629 83 0.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVPiULsvZYiA",
        "outputId": "7525fbb3-35e5-432c-e3de-e56346f18b92"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "url = 'https://www.taifex.com.tw/cht/3/futDailyMarketReport'\n",
        "data = {'queryType': 2,\n",
        "        'marketCode': 1,\n",
        "        'commodity_id': 'MTX',\n",
        "        'queryDate': '2021/11/17', \n",
        "        'MarketCode': 1,\n",
        "        'commodity_idt': 'MTX'}\n",
        "re = requests.post(url, data = data, verify = False) \n",
        "soup = BeautifulSoup(re.text, 'html.parser')\n",
        "table = soup.find('table', {'class': 'table_f'})\n",
        "thead = table.find('tr')\n",
        "\n",
        "title = []\n",
        "for th in thead.find_all('th')[:9]:\n",
        "    title.append(th.text)\n",
        "print(\" \".join(title))\n",
        "future_list = []\n",
        "for row in table.find_all('tr')[1:-1]:\n",
        "    future_info = []\n",
        "    for td in row.find_all('td')[:2]:\n",
        "        future_info.append(td.text.strip())\n",
        "    for td in row.find_all('td')[2:7]:\n",
        "        future_info.append(int(td.text.strip().replace('▲', '').replace('▼', '')))\n",
        "    for td in row.find_all('td')[7:8]:\n",
        "        future_info.append(float(td.text.strip().replace('▲', '').replace('▼', '').replace('%','')))\n",
        "    for td in row.find_all('td')[8:9]:\n",
        "        future_info.append(int(td.text.strip()))\n",
        "    future_list.append(future_info)\n",
        "\n",
        "future_list.sort(key = lambda x: x[8])\n",
        "for i in future_list:\n",
        "    print(\" \".join([str(s) for s in i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "契約 到期月份(週別) 開盤價 最高價 最低價 最後成交價 漲跌價 漲跌% *成交量\n",
            "MTX 202209 17057 17076 17041 17072 35 0.21 22\n",
            "MTX 202206 17463 17478 17438 17472 40 0.23 56\n",
            "MTX 202203 17563 17589 17551 17589 43 0.25 136\n",
            "MTX 202201 17643 17672 17632 17672 39 0.22 481\n",
            "MTX 202112 17689 17722 17680 17721 40 0.23 9716\n",
            "MTX 202111 17712 17743 17697 17740 42 0.24 32410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj80AlxjJHxO"
      },
      "source": [
        "## 檔案處理\n",
        "\n",
        "### 開啟檔案\n",
        "```\n",
        "open('檔案名稱', '開啟模式')\n",
        "open('檔案名稱', 'w') #寫入文字檔\n",
        "open('檔案名稱', 'wb') #寫入二進制檔案（例如圖片）\n",
        "```\n",
        "\n",
        "### 寫入檔案\n",
        "```\n",
        "file.write(寫入的內容)\n",
        "file.close() #讀寫完檔案一定要記得關閉檔案\n",
        "```\n",
        "\n",
        "### try...finally\n",
        "* 開啟檔案時，如果檔案不存在會發生 FileNotFoundError\n",
        "* 可以用 try ... finally 來避免 Error 中斷程式，確保最後一定會正確關閉檔案\n",
        "```\n",
        "try:\n",
        "    file = open('檔案名稱', '開啟模式')\n",
        "    file.write('ccClub Web Crawler')\n",
        "finally:\n",
        "    file.close()\n",
        "```\n",
        "* with ... as 的語法會自動呼叫 close() 函數，是更為簡潔優雅的用法\n",
        "```\n",
        "with open('檔案名稱', '開啟模式') as file:\n",
        "    file.write('ccClub Web Crawler')\n",
        "```\n",
        "\n",
        "### 下載檔案\n",
        "```\n",
        "import requests\n",
        "with open( 檔案名稱, 'wb') as file:  #用二進位制讀寫模式開啟一個空白檔案\n",
        "    r = requests.get( 檔案連結 )     #用 GET 向欲下載的檔案連結送出 request\n",
        "    file.write(r.content)           #寫入用 request.content 取得型別為二進位制的資料\n",
        "    r.close()                       #關閉下載的檔案\n",
        "```\n",
        "\n",
        "### OS 套件\n",
        "```\n",
        "os.path.exists( 檔案路徑 )           #判別檔案路徑是否存在\n",
        "os.path.join( 目標路徑 , 檔案名稱 )   #連接檔案路徑\n",
        "os.path.makedirs( 檔案路徑 )         #創建目錄\n",
        "```\n",
        "\n",
        "### 爬蟲實戰\n",
        "台大考古題下載: http://exam.lib.ntu.edu.tw/graduate \n",
        "\n",
        "爬蟲目標：下載資訊工程學研究所 105 年之後的所有考古試題"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGf7-pMrZfn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a622a4fd-0df5-4862-954e-56701033ac17"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "path = './previousExam'\n",
        "url = 'https://exam.lib.ntu.edu.tw/graduate/term/332%20331%201336%20184%20182%20183%20330%201333%2085%20187%20308%201335%201334%20186%2084%20185%20333%201332%2087%2086%20188%2081%2082%2083'\n",
        "re = requests.get(url, verify = False)\n",
        "soup = BeautifulSoup(re.text, 'html.parser')\n",
        "table = soup.find('table', {'class': 'views-table cols-6'}).find('tbody')\n",
        "\n",
        "file_list = []\n",
        "for row in table.findAll('tr'):    \n",
        "    td = row.findAll('td')\n",
        "    year = td[0].text.strip()\n",
        "    dept = td[1].text.strip()\n",
        "    course = td[2].text.strip()\n",
        "    file_link = td[3].a['href'].split('file=')[1].split('&')[0]\n",
        "    if dept == '資訊工程學研究所' and int(year) >= 105:\n",
        "       if file_link not in file_list:\n",
        "            file_list.append(file_link)\n",
        "            file_name = path + f'/{dept}/{year}/{dept}_{course}_{year}.pdf'\n",
        "\n",
        "            if not os.path.exists(os.path.join(path, dept, year)):\n",
        "                os.makedirs(os.path.join(path, dept, year))\n",
        "\n",
        "            with open(file_name, 'wb') as f:\n",
        "                re_file = requests.get(file_link, verify = False)\n",
        "                f.write(re_file.content)\n",
        "                re_file.close()     \n",
        "\n",
        "nextpage = soup.find('li', {'class': 'pager-next'}).a['href']\n",
        "nextpage_url = urljoin('https://exam.lib.ntu.edu.tw', nextpage)\n",
        "while int(year) >= 105:\n",
        "    re = requests.get(nextpage_url, verify = False)\n",
        "    soup = BeautifulSoup(re.text, 'html.parser')\n",
        "    \n",
        "    table = soup.find('table', {'class': 'views-table cols-6'}).find('tbody')\n",
        "    for row in table.findAll('tr'):\n",
        "        td = row.findAll('td')\n",
        "        year = td[0].text.strip()\n",
        "        dept = td[1].text.strip()\n",
        "        course = td[2].text.strip()\n",
        "        file_link = td[3].a['href'].split('file=')[1].split('&')[0]\n",
        "\n",
        "        if dept == '資訊工程學研究所' and int(year) >= 105:\n",
        "            if file_link not in file_list:\n",
        "                file_list.append(file_link)\n",
        "                file_name = path + f'/{dept}/{year}/{dept}_{course}_{year}.pdf'\n",
        "                if not os.path.exists(os.path.join(path, dept, year)):\n",
        "                    os.makedirs(os.path.join(path, dept, year))\n",
        "\n",
        "                with open(file_name, 'wb') as f:\n",
        "                    re_file = requests.get(file_link, verify = False)\n",
        "                    f.write(re_file.content)\n",
        "                    re_file.close()     \n",
        "    \n",
        "    nextpage = soup.find('li', {'class': 'pager-next'}).a['href']\n",
        "    nextpage_url = urljoin('https://exam.lib.ntu.edu.tw', nextpage)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24mUsCh6NHAo"
      },
      "source": [
        "## 爬山課後練習參考解答"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yz2exutdzns"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://hiking.biji.co'\n",
        "my_params = {'q':'album', 'act':'albums', 'type':3, 'order':'hot'}\n",
        "re = requests.get(url, params=my_params)\n",
        "soup = BeautifulSoup(re.text, 'html.parser')\n",
        "albums = soup.findAll('li', {'class':'card-item album-item shadow-z1'})\n",
        "count = 0\n",
        "for album in albums:\n",
        "    if count == 10:\n",
        "        break\n",
        "        \n",
        "    album_url = url + album.find('a')['href']\n",
        "   \n",
        "    top_photo_view = 0\n",
        "    page = 1\n",
        "    while True:\n",
        "        my_params = {'page':page}\n",
        "\n",
        "        re = requests.get(album_url, params=my_params)\n",
        "        soup = BeautifulSoup(re.text, 'html.parser')\n",
        "        photos = soup.findAll('li', {'class':'card-item img-container shadow-z1'})\n",
        "        if not photos:\n",
        "            break\n",
        "\n",
        "        for photo in photos:\n",
        "            photo_view = int(photo.find('a').find('ul').findAll('li')[2].text.replace(',', ''))\n",
        "            if photo_view > top_photo_view:\n",
        "                top_photo_url = photo.find('a').find('img')['data-src']\n",
        "                top_photo_view = photo_view\n",
        "    \n",
        "        page += 1\n",
        "        album_name = album.find('a')['title']\n",
        "      \n",
        "        path = './hiking' \n",
        "        file_name = f\"./hiking/{album_name}.jpg\"\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "        with open(file_name, 'wb') as f:\n",
        "            r = requests.get(top_photo_url)\n",
        "            f.write(r.content)\n",
        "            r.close\n",
        "        \n",
        "        count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v3dDW1PKjQ1"
      },
      "source": [
        "## Selenium\n",
        "\n",
        "### 設定參數\n",
        "```\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_arguments('xxx')\n",
        "driver = webdriver.Chrome('chromedriver', options=chrome_options)\n",
        "```\n",
        "[ref: chrome arguments](https://www.guru99.com/chrome-options-desiredcapabilities.html)\n",
        "\n",
        "### 開啟/關閉瀏覽器\n",
        "```\n",
        "driver.get('xxx.com')\n",
        "driver.close()\n",
        "driver.quit()\n",
        "```\n",
        "\n",
        "### 尋找網頁元素\n",
        "```\n",
        "driver.find_element_by_xxx(\"yyy\") # 過時用法\n",
        "driver.find_elements_by_xxx(\"yyy\")\n",
        "driver.find_element(\"xxx\", \"yyy\")\n",
        "driver.find_elements(\"xxx\", \"yyy\")\n",
        "```\n",
        "xxx 可以是 id, name, class_name, tag_name, xpath\n",
        "\n",
        "[ref: locating elements](https://selenium-python.readthedocs.io/locating-elements.html)\n",
        "\n",
        "### xpath\n",
        "\n",
        "* XML 定位語言\n",
        "* https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl\n",
        "\n",
        "### 按下按鈕\n",
        "```\n",
        "element = driver.find_element(\"xxx\", \"yyy\")\n",
        "element.click()\n",
        "```\n",
        "\n",
        "### 輸入 / 送出 / 清除文字\n",
        "```\n",
        "element.send_keys(\"ABC\")\n",
        "element.submit()\n",
        "element.clear()\n",
        "```\n",
        "\n",
        "### 其他操作\n",
        "```\n",
        "driver.back()       # 上一頁\n",
        "driver.forward()    # 下一頁\n",
        "driver.refresh()    # 重新整理\n",
        "driver.current_url  # 顯示目前網址\n",
        "driver.title        # 顯示網頁標題\n",
        "```\n",
        "\n",
        "### 網頁原始碼\n",
        "```\n",
        "html_text = driver.page_source\n",
        "soup = BeautifulSoup(html_text, \"html.parser\")\n",
        "```\n",
        "\n",
        "### 資料處理\n",
        "```\n",
        "element.text                  # 拿取文字\n",
        "element.get_attribute(\"href\") # 拿取屬性\n",
        "```\n",
        "\n",
        "### 等待元素出現/可點擊\n",
        "```\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "wait = WebDriverWait(driver, 10)\n",
        "element = wait.until(EC.element_to_be_clickable((\"xpath\", '//a[@data-time=\"30\"]')))\n",
        "```\n",
        "[ref](https://selenium-python.readthedocs.io/waits.html)\n",
        "\n",
        "### 補充資料\n",
        "\n",
        "Selenium 手冊：https://selenium-python.readthedocs.io/index.html\n",
        "\n",
        "Behave 自動化測試腳本：https://behave.readthedocs.io/en/stable/\n",
        "\n",
        "Ruby: cucumber + selenium"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr9ro1ALKkx9",
        "outputId": "0107942f-e8f1-4c72-dfd1-1487c40eec5e"
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('chromedriver', options=chrome_options)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (4.1.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.19.0)\n",
            "Requirement already satisfied: urllib3[secure]~=1.26 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.26.7)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.1.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.2.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
            "Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (36.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (2021.10.8)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (21.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (2.21)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.12.0)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (95.0.4638.69-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PbPvvMgLfbG",
        "outputId": "bc38a534-0ea4-4c8a-d5b3-23e0f986c971"
      },
      "source": [
        "import time\n",
        "url = \"https://www.kktix.com\"\n",
        "driver.get(url)\n",
        "\n",
        "search_input = driver.find_element(\"name\", \"search\")\n",
        "search_input.send_keys(\"展覽\")\n",
        "search_input.submit()\n",
        "time.sleep(2)\n",
        "\n",
        "time_choice = driver.find_element(\"xpath\", '//*[@id=\"dLabe4\"]/i')\n",
        "time_choice.click()\n",
        "# time.sleep(2)\n",
        "\n",
        "# this_month = driver.find_element(\"xpath\", '//a[@data-time=\"30\"]')\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "wait = WebDriverWait(driver, 10)\n",
        "this_month = wait.until(EC.element_to_be_clickable((\"xpath\", '//a[@data-time=\"30\"]')))\n",
        "this_month.click()\n",
        "time.sleep(2)\n",
        "\n",
        "events = driver.find_elements(\"xpath\", '//*[@class=\"events clearfix\"]//h2')\n",
        "for event in events:\n",
        "  print(event.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "《WeWORD 字我訂造：流行歌詞及其創造的》新媒體展\n",
            "貓・美術館 線上展 走進貓次元 Step Into Cat Art\n",
            "印象莫內—光影體驗展\n",
            "中山區包場空間/共享空間/各式活動\n",
            "印象莫內—光影體驗展（高雄站）\n",
            "小王子的藝想世界　75周年特展\n",
            "『幸運草美術師生聯展』\n",
            "【2021 打開新竹｜開放空間預約】21_江雨桐手作工坊\n",
            "【2021 打開新竹｜開放空間預約】45_春室\n",
            "【2021 打開新竹｜開放空間預約】09_藝站\n",
            "【2021 打開新竹｜開放空間預約】19_新竹市鐵道藝術村\n",
            "2021 GAMFORCE 電競嘉年華\n"
          ]
        }
      ]
    }
  ]
}